# Statistics and Machine Learning Learning Log

This repository contains structured notes from my study of Statistics alongside core Machine Learning topics. The objective is to understand concepts at a foundational level, with emphasis on intuition, reasoning, and their application in ML.

The content is written in my own words and reflects my current level of understanding. Concepts may be updated over time as my depth improves 

**Purpose**

The purpose of this repository is to:

- Build a rigorous foundation in statistical thinking as it applies to ML

- Understand why core ML algorithms work, rather than only how to use them

- Record insights, questions, and knowledge gaps for future reflection

- Create a public, chronological record of technical progress

- Maintain a research-oriented learning habit

This is an evolving record and will be updated as I refine earlier concepts and correct misconceptions.

**Learning Approach**

The learning approach is based on integrating Statistics and Machine Learning rather than studying them as separate subjects.

Every statistical concept is connected to a relevant ML concept

 -  Each entry is written in my own understanding, not copied definitions

 -  Concepts are reinforced through small code experiments

 -  Mistakes, confusions, and open questions are documented explicitly

 -  The log is intentionally short and focused per entry

The structure encourages depth over breadth.

**Structure**
The repository is organized by conceptual domains. Each subfolder contains dated log entries, one per learning session.
root/
**Repository Structure**

The repository is organized by conceptual domains. Each subfolder contains dated log entries, one per learning session.

```
.
├── 01-descriptive-statistics/
│   ├── YYYY-MM-DD-population-vs-sample.md
│   ├── YYYY-MM-DD-types-of-variables.md
│
├── 02-inferential-statistics/
│   ├── ...
│
├── 03-regression/
│   ├── ...
│
├── 04-classification/
│   ├── ...
│
├── images/        # supporting figures or plots
├── notebooks/     # experiments in Jupyter notebooks
└── README.md
```

**Log Format**
Each log entry follows a uniform format to ensure consistency and traceability of learning.
```
# Concept Title

## Understanding
Brief explanation of the concept in my own words (not more than 6–8 lines).

## Example
A concrete example from a real dataset or a relevant application domain.

## Connection to Machine Learning
Why this matters in ML, and where this concept appears in ML practice or theory.

## Short Experiment (optional)
A brief code experiment validating or exploring the idea.

## Questions and Notes
Knowledge gaps, uncertainties, and follow-up items for future work.
```
**Relationship Between Statistics and ML**
This repository is based on the principle that machine learning is fundamentally a statistical discipline. Some examples of the connection:

- Train/test split is a sampling problem

- Mean squared error is a variance measure over prediction errors

- Logistic regression is a probabilistic model with a sigmoid link

- Cross-entropy loss is rooted in information theory

- Regularization manages the bias–variance trade-off

- Model evaluation relies on hypothesis testing and statistical significance

- Neural network optimization can be framed statistically through likelihood

Therefore, each statistical concept will be linked with its role in ML wherever applicable.

**Sources**

This repository is informed by multiple sources including textbooks, academic lectures, online courses, and research papers.
No definitions or content are copied into the log.
Only processed understanding appears here.

References to specific sources (if required) will be cited within individual entries

**Progress and Revision**

As understanding deepens, earlier entries may be revised. Updates will be reflected with commit history to maintain transparency of progress and evolution of understanding.

Periodic summaries will consolidate multiple entries into a higher-level synthesis.

**Disclaimer**

This is a personal learning record.
It is not intended as instructional material or a formal tutorial.
Concepts documented here may initially contain errors, partial understanding, or open questions. These are intentionally preserved for revision.


